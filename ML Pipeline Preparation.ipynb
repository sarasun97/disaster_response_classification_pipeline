{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "Follow the instructions below to help you create your ML pipeline.\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from sqlalchemy import create_engine\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix, precision_score,\\\n",
    "recall_score,accuracy_score,  f1_score,  make_scorer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import nltk\n",
    "\n",
    "from nltk import word_tokenize\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    # load data from database\n",
    "    #engine = create_engine('sqlite:///DisasterResponse_new.db')\n",
    "    #df = pd.read_sql(\"SELECT * FROM DisasterResponse_new\", engine)\n",
    "    df = pd.read_csv(\"DisasterResponse_new.csv\")\n",
    "    X = df.message\n",
    "    y = df.loc[:,\"related\":\"direct_report\"]\n",
    "    category_names=y.columns\n",
    "    return X, y,category_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the first five messages as a sample to take a look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Weather update - a cold front from Cuba that c...\n",
      "1              Is the Hurricane over or is it not over\n",
      "2                      Looking for someone but no name\n",
      "3    UN reports Leogane 80-90 destroyed. Only Hospi...\n",
      "4    says: west side of Haiti, rest of the country ...\n",
      "Name: message, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3263: DtypeWarning: Columns (3) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>search_and_rescue</th>\n",
       "      <th>security</th>\n",
       "      <th>military</th>\n",
       "      <th>child_alone</th>\n",
       "      <th>...</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   related  request  offer  aid_related  medical_help  medical_products  \\\n",
       "0        1        0      0            0             0                 0   \n",
       "1        1        0      0            1             0                 0   \n",
       "2        1        0      0            0             0                 0   \n",
       "3        1        1      0            1             0                 1   \n",
       "4        1        0      0            0             0                 0   \n",
       "\n",
       "   search_and_rescue  security  military  child_alone  ...  aid_centers  \\\n",
       "0                  0         0         0            0  ...            0   \n",
       "1                  0         0         0            0  ...            0   \n",
       "2                  0         0         0            0  ...            0   \n",
       "3                  0         0         0            0  ...            0   \n",
       "4                  0         0         0            0  ...            0   \n",
       "\n",
       "   other_infrastructure  weather_related  floods  storm  fire  earthquake  \\\n",
       "0                     0                0       0      0     0           0   \n",
       "1                     0                1       0      1     0           0   \n",
       "2                     0                0       0      0     0           0   \n",
       "3                     0                0       0      0     0           0   \n",
       "4                     0                0       0      0     0           0   \n",
       "\n",
       "   cold  other_weather  direct_report  \n",
       "0     0              0              0  \n",
       "1     0              0              0  \n",
       "2     0              0              0  \n",
       "3     0              0              0  \n",
       "4     0              0              0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,y,category_names=load_data()\n",
    "print(X[:5])\n",
    "y.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Normalize text data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sequence of functions used to  clean up HTML markups, expand contractions, stem and lemmatize, remove special characters, get rid of stop words, and remove accents from characters, etc. is defined in the notebook called Text_Normalization_Function. Run the notebook and the functions will be available in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing c:\\users\\nsun9\\appdata\\local\\pip\\cache\\wheels\\4f\\85\\2a\\67a30aa6cf144eca0c159f337ce5166df2213c4cde9e699cbe\\html_parser-0.2-py3-none-any.whl\n",
      "Requirement already satisfied: ply in d:\\programs\\anaconda3\\lib\\site-packages (from html.parser) (3.11)\n",
      "Installing collected packages: html.parser\n",
      "Successfully installed html.parser\n",
      "Requirement already satisfied: nltk in d:\\programs\\anaconda3\\lib\\site-packages (3.5)\n",
      "Requirement already satisfied: click in d:\\programs\\anaconda3\\lib\\site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: tqdm in d:\\programs\\anaconda3\\lib\\site-packages (from nltk) (4.47.0)\n",
      "Requirement already satisfied: joblib in d:\\programs\\anaconda3\\lib\\site-packages (from nltk) (0.16.0)\n",
      "Requirement already satisfied: regex in d:\\programs\\anaconda3\\lib\\site-packages (from nltk) (2020.6.8)\n",
      "Requirement already satisfied: pattern3 in d:\\programs\\anaconda3\\lib\\site-packages (3.0.0)\n",
      "Requirement already satisfied: docx in d:\\programs\\anaconda3\\lib\\site-packages (from pattern3) (0.2.4)\n",
      "Requirement already satisfied: pdfminer.six in d:\\programs\\anaconda3\\lib\\site-packages (from pattern3) (20201018)\n",
      "Requirement already satisfied: beautifulsoup4 in d:\\programs\\anaconda3\\lib\\site-packages (from pattern3) (4.9.1)\n",
      "Requirement already satisfied: simplejson in d:\\programs\\anaconda3\\lib\\site-packages (from pattern3) (3.17.2)\n",
      "Requirement already satisfied: pdfminer3k in d:\\programs\\anaconda3\\lib\\site-packages (from pattern3) (1.3.4)\n",
      "Requirement already satisfied: cherrypy in d:\\programs\\anaconda3\\lib\\site-packages (from pattern3) (18.6.0)\n",
      "Requirement already satisfied: feedparser in d:\\programs\\anaconda3\\lib\\site-packages (from pattern3) (6.0.2)\n",
      "Requirement already satisfied: Pillow>=2.0 in d:\\programs\\anaconda3\\lib\\site-packages (from docx->pattern3) (7.2.0)\n",
      "Requirement already satisfied: lxml in d:\\programs\\anaconda3\\lib\\site-packages (from docx->pattern3) (4.5.2)\n",
      "Requirement already satisfied: chardet; python_version > \"3.0\" in d:\\programs\\anaconda3\\lib\\site-packages (from pdfminer.six->pattern3) (3.0.4)\n",
      "Requirement already satisfied: sortedcontainers in d:\\programs\\anaconda3\\lib\\site-packages (from pdfminer.six->pattern3) (2.2.2)\n",
      "Requirement already satisfied: cryptography in d:\\programs\\anaconda3\\lib\\site-packages (from pdfminer.six->pattern3) (2.9.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\programs\\anaconda3\\lib\\site-packages (from beautifulsoup4->pattern3) (2.0.1)\n",
      "Requirement already satisfied: ply in d:\\programs\\anaconda3\\lib\\site-packages (from pdfminer3k->pattern3) (3.11)\n",
      "Requirement already satisfied: zc.lockfile in d:\\programs\\anaconda3\\lib\\site-packages (from cherrypy->pattern3) (2.0)\n",
      "Requirement already satisfied: pywin32; sys_platform == \"win32\" in d:\\programs\\anaconda3\\lib\\site-packages (from cherrypy->pattern3) (227)\n",
      "Requirement already satisfied: more-itertools in d:\\programs\\anaconda3\\lib\\site-packages (from cherrypy->pattern3) (8.4.0)\n",
      "Requirement already satisfied: cheroot>=8.2.1 in d:\\programs\\anaconda3\\lib\\site-packages (from cherrypy->pattern3) (8.5.2)\n",
      "Requirement already satisfied: portend>=2.1.1 in d:\\programs\\anaconda3\\lib\\site-packages (from cherrypy->pattern3) (2.7.1)\n",
      "Requirement already satisfied: jaraco.collections in d:\\programs\\anaconda3\\lib\\site-packages (from cherrypy->pattern3) (3.3.0)\n",
      "Requirement already satisfied: sgmllib3k in d:\\programs\\anaconda3\\lib\\site-packages (from feedparser->pattern3) (1.0.0)\n",
      "Requirement already satisfied: six>=1.4.1 in d:\\programs\\anaconda3\\lib\\site-packages (from cryptography->pdfminer.six->pattern3) (1.15.0)\n",
      "Requirement already satisfied: cffi!=1.11.3,>=1.8 in d:\\programs\\anaconda3\\lib\\site-packages (from cryptography->pdfminer.six->pattern3) (1.14.0)\n",
      "Requirement already satisfied: setuptools in d:\\programs\\anaconda3\\lib\\site-packages (from zc.lockfile->cherrypy->pattern3) (49.2.0.post20200714)\n",
      "Requirement already satisfied: jaraco.functools in d:\\programs\\anaconda3\\lib\\site-packages (from cheroot>=8.2.1->cherrypy->pattern3) (3.3.0)\n",
      "Requirement already satisfied: tempora>=1.8 in d:\\programs\\anaconda3\\lib\\site-packages (from portend>=2.1.1->cherrypy->pattern3) (4.0.1)\n",
      "Requirement already satisfied: jaraco.text in d:\\programs\\anaconda3\\lib\\site-packages (from jaraco.collections->cherrypy->pattern3) (3.5.0)\n",
      "Requirement already satisfied: jaraco.classes in d:\\programs\\anaconda3\\lib\\site-packages (from jaraco.collections->cherrypy->pattern3) (3.2.1)\n",
      "Requirement already satisfied: pycparser in d:\\programs\\anaconda3\\lib\\site-packages (from cffi!=1.11.3,>=1.8->cryptography->pdfminer.six->pattern3) (2.20)\n",
      "Requirement already satisfied: pytz in d:\\programs\\anaconda3\\lib\\site-packages (from tempora>=1.8->portend>=2.1.1->cherrypy->pattern3) (2020.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\nsun9\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\nsun9\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\nsun9\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\nsun9\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "%run ./Text_Normalization_Function.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The normalize_corpus can be used as a customized preprocessor in CountVectorizer.\\\n",
    "**preprocessor** should be a callable, default=None. Override the preprocessing (strip_accents and lowercase) stage while preserving the tokenizing and n-grams generation steps. It should return a text **(not a series or list)**. \n",
    "\n",
    "However, if a function is used to normalize the corpus before feeding to CountVectorizer, the function should return a series or list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the first five messages as a sample to take a look at result after CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cold</th>\n",
       "      <th>could</th>\n",
       "      <th>country</th>\n",
       "      <th>croix</th>\n",
       "      <th>cuba</th>\n",
       "      <th>desperately</th>\n",
       "      <th>destroyed</th>\n",
       "      <th>front</th>\n",
       "      <th>functioning</th>\n",
       "      <th>haiti</th>\n",
       "      <th>...</th>\n",
       "      <th>side</th>\n",
       "      <th>someone</th>\n",
       "      <th>st</th>\n",
       "      <th>supply</th>\n",
       "      <th>today</th>\n",
       "      <th>tonight</th>\n",
       "      <th>un</th>\n",
       "      <th>update</th>\n",
       "      <th>weather</th>\n",
       "      <th>west</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cold  could  country  croix  cuba  desperately  destroyed  front  \\\n",
       "0     1      1        0      0     1            0          0      1   \n",
       "1     0      0        0      0     0            0          0      0   \n",
       "2     0      0        0      0     0            0          0      0   \n",
       "3     0      0        0      1     0            1          1      0   \n",
       "4     0      0        1      0     0            0          0      0   \n",
       "\n",
       "   functioning  haiti  ...  side  someone  st  supply  today  tonight  un  \\\n",
       "0            0      1  ...     0        0   0       0      0        0   0   \n",
       "1            0      0  ...     0        0   0       0      0        0   0   \n",
       "2            0      0  ...     0        1   0       0      0        0   0   \n",
       "3            1      0  ...     0        0   1       1      0        0   1   \n",
       "4            0      1  ...     1        0   0       0      1        1   0   \n",
       "\n",
       "   update  weather  west  \n",
       "0       1        1     0  \n",
       "1       0        0     0  \n",
       "2       0        0     0  \n",
       "3       0        0     0  \n",
       "4       0        0     1  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_vectorizer = CountVectorizer(preprocessor=normalize_corpus)\n",
    "NORM_corpus_train_bow = bow_vectorizer.fit_transform(X[:5])\n",
    "NORM_corpus_train_bow_table= pd.DataFrame(data = NORM_corpus_train_bow.todense(),\n",
    "                                           columns = bow_vectorizer.get_feature_names())\n",
    "NORM_corpus_train_bow_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Add other features besides the TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other characteristics of the text, such as length, may also affect the results. I defined a function to count the number of tokens contained in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Text_Length_Extractor(BaseEstimator, TransformerMixin):\n",
    "    def get_length(self, text):\n",
    "        length=len(word_tokenize(text))\n",
    "        return length\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_length = pd.Series(X).apply(self.get_length)\n",
    "        # In order to use FeatureUnion to combine the Text_Length_Extractor with the text_pipeline,\n",
    "        # We must convert X_length into a dataframe. Otherwise, ValueError: blocks[0,:] has incompatible row dimensions. \n",
    "        return pd.DataFrame(X_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Build a machine learning pipeline\n",
    "This machine pipeline should take in the `message` column as input and output classification results on the other 36 categories in the dataset. You may find the [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) helpful for predicting multiple target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "        ('text_pipeline',Pipeline([\n",
    "            ('vect', CountVectorizer(preprocessor=normalize_corpus)),\n",
    "            ('tfidf', TfidfTransformer())\n",
    "        ])),\n",
    "        ('text_length',Text_Length_Extractor())\n",
    "    ])),\n",
    "        \n",
    "    ('clf', MultiOutputClassifier(estimator=RandomForestClassifier(random_state=42)))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Train pipeline\n",
    "- Split data into train and test sets\n",
    "- Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Test your model\n",
    "Report the f1 score, precision and recall for each output category of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The y_pred is a numpy array with a shape of (6554, 36), so we have to access it by referring to its index number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " ...\n",
      " [1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]]\n",
      "[1 1 1 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)\n",
    "print(y_pred[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The y_test is a pd dataframe, if we want to access it by referring to its column number, we can use df.iloc, integer-location based indexing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>search_and_rescue</th>\n",
       "      <th>security</th>\n",
       "      <th>military</th>\n",
       "      <th>child_alone</th>\n",
       "      <th>...</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12720</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10777</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12457</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11980</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       related  request  offer  aid_related  medical_help  medical_products  \\\n",
       "12720        1        0      0            0             0                 0   \n",
       "10777        1        1      0            1             0                 0   \n",
       "1273         0        0      0            0             0                 0   \n",
       "12457        1        0      0            0             0                 0   \n",
       "11980        1        0      0            1             1                 0   \n",
       "\n",
       "       search_and_rescue  security  military  child_alone  ...  aid_centers  \\\n",
       "12720                  0         0         0            0  ...            0   \n",
       "10777                  0         0         1            0  ...            0   \n",
       "1273                   0         0         0            0  ...            0   \n",
       "12457                  0         0         0            0  ...            0   \n",
       "11980                  1         1         0            0  ...            0   \n",
       "\n",
       "       other_infrastructure  weather_related  floods  storm  fire  earthquake  \\\n",
       "12720                     0                1       0      1     0           0   \n",
       "10777                     0                1       0      0     0           0   \n",
       "1273                      0                0       0      0     0           0   \n",
       "12457                     0                1       0      1     0           0   \n",
       "11980                     0                1       1      0     0           0   \n",
       "\n",
       "       cold  other_weather  direct_report  \n",
       "12720     0              0              1  \n",
       "10777     1              0              0  \n",
       "1273      0              0              0  \n",
       "12457     0              0              0  \n",
       "11980     0              0              0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter average: required for multiclass/multilabel targets. \n",
    "\n",
    "Binary:Only report results for the class specified by pos_label (default is 1).\n",
    "\n",
    "Macro average (averaging the unweighted mean per label), weighted average (averaging the support-weighted mean per label).\n",
    "\n",
    "Take F1 score as an example:\n",
    "\n",
    "Macro F1 calculates the F1 separated by class but not using weights for the aggregation: F1class1+F1class2+⋅⋅⋅+F1classN, which resuls in a bigger penalisation when the model does not perform well with the minority classes(when there is imbalance)\n",
    "\n",
    "Weighted F1 score calculates the F1 score for each class independently but when it adds them together uses a weight that depends on the number of true labels of each class: F1class1∗W1+F1class2∗W2+⋅⋅⋅+F1classN∗WN.Therefore favouring the majority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.38      0.50      1566\n",
      "           1       0.83      0.95      0.89      4988\n",
      "\n",
      "    accuracy                           0.81      6554\n",
      "   macro avg       0.76      0.67      0.69      6554\n",
      "weighted avg       0.80      0.81      0.79      6554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test.iloc[:,0], y_pred[:,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, I use the default average parameter, binary. The recall and precision for some small categories such as offer and child alone are almost zero. The classifier classified almost everything as 0 due to an imbalance in the training data\n",
    "\n",
    "Unlike the common problem with only one column of y, this project has 36 columns of y. In order to evaluate the prediction of each column, I use for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Programs\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Programs\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1464: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Accuracy  Precision    Recall       F_1\n",
      "related                 0.813244   0.830639  0.947875  0.885393\n",
      "request                 0.897315   0.837446  0.507030  0.631637\n",
      "offer                   0.995728   0.000000  0.000000  0.000000\n",
      "aid_related             0.778761   0.741923  0.707761  0.724439\n",
      "medical_help            0.925084   0.569231  0.074000  0.130973\n",
      "medical_products        0.959872   0.763158  0.102473  0.180685\n",
      "search_and_rescue       0.974825   0.769231  0.058140  0.108108\n",
      "security                0.980012   0.500000  0.007634  0.015038\n",
      "military                0.967958   0.666667  0.064516  0.117647\n",
      "child_alone             1.000000   0.000000  0.000000  0.000000\n",
      "water                   0.956668   0.855000  0.401408  0.546326\n",
      "food                    0.943241   0.843750  0.615282  0.711628\n",
      "shelter                 0.943546   0.840909  0.446552  0.583333\n",
      "clothing                0.984284   0.800000  0.073394  0.134454\n",
      "money                   0.975740   0.500000  0.012579  0.024540\n",
      "missing_people          0.991150   1.000000  0.016949  0.033333\n",
      "refugees                0.964602   1.000000  0.021097  0.041322\n",
      "death                   0.961398   0.791667  0.193220  0.310627\n",
      "other_aid               0.875343   0.566038  0.036408  0.068415\n",
      "infrastructure_related  0.940189   0.000000  0.000000  0.000000\n",
      "transport               0.958804   0.869565  0.069686  0.129032\n",
      "buildings               0.956820   0.729730  0.090000  0.160237\n",
      "electricity             0.982606   0.833333  0.042373  0.080645\n",
      "tools                   0.994355   0.000000  0.000000  0.000000\n",
      "hospitals               0.989930   0.000000  0.000000  0.000000\n",
      "shops                   0.995423   0.000000  0.000000  0.000000\n",
      "aid_centers             0.988099   0.000000  0.000000  0.000000\n",
      "other_infrastructure    0.962618   0.000000  0.000000  0.000000\n",
      "weather_related         0.883125   0.850641  0.713441  0.776023\n",
      "floods                  0.952853   0.920152  0.456604  0.610340\n",
      "storm                   0.938511   0.803783  0.515152  0.627886\n",
      "fire                    0.990082   1.000000  0.029851  0.057971\n",
      "earthquake              0.971163   0.887900  0.798400  0.840775\n",
      "cold                    0.981996   1.000000  0.099237  0.180556\n",
      "other_weather           0.948276   0.588235  0.029240  0.055710\n",
      "direct_report           0.862984   0.819805  0.390867  0.529350\n"
     ]
    }
   ],
   "source": [
    "metrics_list_all=[]\n",
    "for col in range(y_test.shape[1]):\n",
    "    accuracy = accuracy_score(y_test.iloc[:,col], y_pred[:,col])\n",
    "    precision=precision_score(y_test.iloc[:,col], y_pred[:,col])\n",
    "    recall = recall_score(y_test.iloc[:,col], y_pred[:,col])\n",
    "    f_1 = f1_score(y_test.iloc[:,col], y_pred[:,col])\n",
    "    metrics_list=[accuracy,precision,recall,f_1]\n",
    "    metrics_list_all.append(metrics_list)\n",
    "metrics_df=pd.DataFrame(metrics_list_all,index=category_names,columns=[\"Accuracy\",\"Precision\",\"Recall\",\"F_1\"])\n",
    "print(metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I calculate the accuracy score directly, it will give back very weird result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.25587427525175466, 0.25587427525175466)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test.values, y_pred),pipeline.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, if use reshape to flatten the data from having 36 different columns to 1 column (appending data of each column one after the other), the result will be the same as using for loop to calculate the accuracy score of each column and then calculate the average\n",
    "\n",
    "numpy.reshape(a, newshape, order='C') gives a new shape to an array without changing its data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9496278778015123"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test.values.reshape(-1,1), y_pred.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average accuracy score among all categories is 0.9496,\n",
      "the average precision score score among all categories is 0.6161,\n",
      "the average recall score among all categories is 0.2089,\n",
      "the average F 1 score among all categories is 0.2582\n"
     ]
    }
   ],
   "source": [
    "print((\"The average accuracy score among all categories is {:.4f},\\nthe average precision score score among all categories is {:.4f},\\nthe average recall score among all categories is {:.4f},\\nthe average F 1 score among all categories is {:.4f}\").format(metrics_df.mean()[\"Accuracy\"],metrics_df.mean()[\"Precision\"],metrics_df.mean()[\"Recall\"],metrics_df.mean()[\"F_1\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Improve your model\n",
    "Use grid search to find better parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a score used in scoring parameter\n",
    "def avg_accuracy(y_test, y_pred):\n",
    "    \"\"\"\n",
    "    This is the score_func used in make_scorer, which would be used in in GridSearchCV \n",
    "    \"\"\"\n",
    "    avg_accuracy=accuracy_score(y_test.values.reshape(-1,1), y_pred.reshape(-1,1))\n",
    "    \n",
    "    return avg_accuracy\n",
    "avg_accuracy_cv = make_scorer(avg_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['memory',\n",
       " 'steps',\n",
       " 'verbose',\n",
       " 'features',\n",
       " 'clf',\n",
       " 'features__n_jobs',\n",
       " 'features__transformer_list',\n",
       " 'features__transformer_weights',\n",
       " 'features__verbose',\n",
       " 'features__text_pipeline',\n",
       " 'features__text_length',\n",
       " 'features__text_pipeline__memory',\n",
       " 'features__text_pipeline__steps',\n",
       " 'features__text_pipeline__verbose',\n",
       " 'features__text_pipeline__vect',\n",
       " 'features__text_pipeline__tfidf',\n",
       " 'features__text_pipeline__vect__analyzer',\n",
       " 'features__text_pipeline__vect__binary',\n",
       " 'features__text_pipeline__vect__decode_error',\n",
       " 'features__text_pipeline__vect__dtype',\n",
       " 'features__text_pipeline__vect__encoding',\n",
       " 'features__text_pipeline__vect__input',\n",
       " 'features__text_pipeline__vect__lowercase',\n",
       " 'features__text_pipeline__vect__max_df',\n",
       " 'features__text_pipeline__vect__max_features',\n",
       " 'features__text_pipeline__vect__min_df',\n",
       " 'features__text_pipeline__vect__ngram_range',\n",
       " 'features__text_pipeline__vect__preprocessor',\n",
       " 'features__text_pipeline__vect__stop_words',\n",
       " 'features__text_pipeline__vect__strip_accents',\n",
       " 'features__text_pipeline__vect__token_pattern',\n",
       " 'features__text_pipeline__vect__tokenizer',\n",
       " 'features__text_pipeline__vect__vocabulary',\n",
       " 'features__text_pipeline__tfidf__norm',\n",
       " 'features__text_pipeline__tfidf__smooth_idf',\n",
       " 'features__text_pipeline__tfidf__sublinear_tf',\n",
       " 'features__text_pipeline__tfidf__use_idf',\n",
       " 'clf__estimator__bootstrap',\n",
       " 'clf__estimator__ccp_alpha',\n",
       " 'clf__estimator__class_weight',\n",
       " 'clf__estimator__criterion',\n",
       " 'clf__estimator__max_depth',\n",
       " 'clf__estimator__max_features',\n",
       " 'clf__estimator__max_leaf_nodes',\n",
       " 'clf__estimator__max_samples',\n",
       " 'clf__estimator__min_impurity_decrease',\n",
       " 'clf__estimator__min_impurity_split',\n",
       " 'clf__estimator__min_samples_leaf',\n",
       " 'clf__estimator__min_samples_split',\n",
       " 'clf__estimator__min_weight_fraction_leaf',\n",
       " 'clf__estimator__n_estimators',\n",
       " 'clf__estimator__n_jobs',\n",
       " 'clf__estimator__oob_score',\n",
       " 'clf__estimator__random_state',\n",
       " 'clf__estimator__verbose',\n",
       " 'clf__estimator__warm_start',\n",
       " 'clf__estimator',\n",
       " 'clf__n_jobs']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at what parameters are available to be tuned\n",
    "list(pipeline.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[CV] clf__estimator__max_depth=15, clf__estimator__n_estimators=100 ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__max_depth=15, clf__estimator__n_estimators=100, score=0.929, total= 1.2min\n",
      "[CV] clf__estimator__max_depth=15, clf__estimator__n_estimators=100 ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__max_depth=15, clf__estimator__n_estimators=100, score=0.929, total= 1.2min\n",
      "[CV] clf__estimator__max_depth=15, clf__estimator__n_estimators=100 ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  2.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__max_depth=15, clf__estimator__n_estimators=100, score=0.928, total= 1.2min\n",
      "[CV] clf__estimator__max_depth=15, clf__estimator__n_estimators=250 ..\n",
      "[CV]  clf__estimator__max_depth=15, clf__estimator__n_estimators=250, score=0.929, total= 1.6min\n",
      "[CV] clf__estimator__max_depth=15, clf__estimator__n_estimators=250 ..\n",
      "[CV]  clf__estimator__max_depth=15, clf__estimator__n_estimators=250, score=0.929, total= 1.7min\n",
      "[CV] clf__estimator__max_depth=15, clf__estimator__n_estimators=250 ..\n",
      "[CV]  clf__estimator__max_depth=15, clf__estimator__n_estimators=250, score=0.928, total= 1.7min\n",
      "[CV] clf__estimator__max_depth=30, clf__estimator__n_estimators=100 ..\n",
      "[CV]  clf__estimator__max_depth=30, clf__estimator__n_estimators=100, score=0.933, total= 1.8min\n",
      "[CV] clf__estimator__max_depth=30, clf__estimator__n_estimators=100 ..\n",
      "[CV]  clf__estimator__max_depth=30, clf__estimator__n_estimators=100, score=0.933, total= 1.9min\n",
      "[CV] clf__estimator__max_depth=30, clf__estimator__n_estimators=100 ..\n",
      "[CV]  clf__estimator__max_depth=30, clf__estimator__n_estimators=100, score=0.933, total= 1.8min\n",
      "[CV] clf__estimator__max_depth=30, clf__estimator__n_estimators=250 ..\n",
      "[CV]  clf__estimator__max_depth=30, clf__estimator__n_estimators=250, score=0.933, total= 3.0min\n",
      "[CV] clf__estimator__max_depth=30, clf__estimator__n_estimators=250 ..\n",
      "[CV]  clf__estimator__max_depth=30, clf__estimator__n_estimators=250, score=0.934, total= 3.0min\n",
      "[CV] clf__estimator__max_depth=30, clf__estimator__n_estimators=250 ..\n",
      "[CV]  clf__estimator__max_depth=30, clf__estimator__n_estimators=250, score=0.933, total= 3.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed: 23.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('features',\n",
       "                                        FeatureUnion(transformer_list=[('text_pipeline',\n",
       "                                                                        Pipeline(steps=[('vect',\n",
       "                                                                                         CountVectorizer(preprocessor=<function normalize_corpus at 0x000001601B0118B0>)),\n",
       "                                                                                        ('tfidf',\n",
       "                                                                                         TfidfTransformer())])),\n",
       "                                                                       ('text_length',\n",
       "                                                                        Text_Length_Extractor())])),\n",
       "                                       ('clf',\n",
       "                                        MultiOutputClassifier(estimator=RandomForestClassifier(random_state=42)))]),\n",
       "             param_grid={'clf__estimator__max_depth': [15, 30],\n",
       "                         'clf__estimator__n_estimators': [100, 250]},\n",
       "             scoring=make_scorer(avg_accuracy), verbose=3)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = parameters = {\n",
    "    #'features__text_pipeline__vect__ngram_range': ((1, 1), (1, 2)),  \n",
    "    'clf__estimator__max_depth': [15, 30],  \n",
    "    'clf__estimator__n_estimators': [100, 250]}\n",
    "\n",
    "cv = GridSearchCV(\n",
    "    pipeline, \n",
    "    param_grid=parameters,\n",
    "    cv=3,\n",
    "    scoring=avg_accuracy_cv, \n",
    "    verbose=3)\n",
    "\n",
    "cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Test your model\n",
    "Show the accuracy, precision, and recall of the tuned model.  \n",
    "\n",
    "Since this project focuses on code quality, process, and  pipelines, there is no minimum performance metric needed to pass. However, make sure to fine tune your models for accuracy, precision and recall to make your project stand out - especially for your portfolio!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test,category_names):\n",
    "    \"\"\"\n",
    "    The evaluate_model function will return the accuracy, precision, and recall, and f1 scores for each output category of the dataset.\n",
    "\n",
    "    INPUTS:\n",
    "        model- a trained model for evaluation\n",
    "        X_test - a panda data frame or Numpy array, contains the untouched values of features. \n",
    "        y_pred - a Numpy array, contains predicted category values of the messages. \n",
    "        \n",
    "    OUTPUT:\n",
    "    metrics_df, a panda dataframe that contains accuracy, precision, and recall, and f1 scores for each output category of the dataset.\n",
    "    \"\"\"\n",
    "    y_pred=model.predict(X_test)\n",
    "    metrics_list_all=[]\n",
    "    for col in range(y_test.shape[1]):\n",
    "        accuracy = accuracy_score(y_test.iloc[:,col], y_pred[:,col])\n",
    "        precision=precision_score(y_test.iloc[:,col], y_pred[:,col])\n",
    "        recall = recall_score(y_test.iloc[:,col], y_pred[:,col])\n",
    "        f_1 = f1_score(y_test.iloc[:,col], y_pred[:,col])\n",
    "        metrics_list=[accuracy,precision,recall,f_1]\n",
    "        metrics_list_all.append(metrics_list)\n",
    "    metrics_df=pd.DataFrame(metrics_list_all,index=category_names,columns=[\"Accuracy\",\"Precision\",\"Recall\",\"F_1\"])\n",
    "    print(metrics_df)\n",
    "    print(\"----------------------------------------------------------------------\")\n",
    "    print((\"The average accuracy score among all categories is {:.4f},\\nthe average precision score score among all categories is {:.4f},\\nthe average recall score among all categories is {:.4f},\\nthe average F 1 score among all categories is {:.4f}\").format(metrics_df.mean()[\"Accuracy\"],metrics_df.mean()[\"Precision\"],metrics_df.mean()[\"Recall\"],metrics_df.mean()[\"F_1\"]))\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best model and store it as best_randomforest\n",
    "best_randomforest=cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Programs\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Programs\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1464: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Accuracy  Precision    Recall       F_1\n",
      "related                 0.761520   0.761570  0.999599  0.864499\n",
      "request                 0.839335   0.967033  0.077329  0.143206\n",
      "offer                   0.995728   0.000000  0.000000  0.000000\n",
      "aid_related             0.727037   0.857030  0.402896  0.548118\n",
      "medical_help            0.923711   0.500000  0.002000  0.003984\n",
      "medical_products        0.956973   1.000000  0.003534  0.007042\n",
      "search_and_rescue       0.973756   0.000000  0.000000  0.000000\n",
      "security                0.980012   0.000000  0.000000  0.000000\n",
      "military                0.966890   0.000000  0.000000  0.000000\n",
      "child_alone             1.000000   0.000000  0.000000  0.000000\n",
      "water                   0.935154   1.000000  0.002347  0.004684\n",
      "food                    0.887244   1.000000  0.009383  0.018592\n",
      "shelter                 0.912420   1.000000  0.010345  0.020478\n",
      "clothing                0.983522   1.000000  0.009174  0.018182\n",
      "money                   0.975740   0.000000  0.000000  0.000000\n",
      "missing_people          0.990998   0.000000  0.000000  0.000000\n",
      "refugees                0.963839   0.000000  0.000000  0.000000\n",
      "death                   0.955294   1.000000  0.006780  0.013468\n",
      "other_aid               0.874275   0.000000  0.000000  0.000000\n",
      "infrastructure_related  0.940647   0.000000  0.000000  0.000000\n",
      "transport               0.956210   0.000000  0.000000  0.000000\n",
      "buildings               0.954226   0.000000  0.000000  0.000000\n",
      "electricity             0.981996   0.000000  0.000000  0.000000\n",
      "tools                   0.994355   0.000000  0.000000  0.000000\n",
      "hospitals               0.989930   0.000000  0.000000  0.000000\n",
      "shops                   0.995423   0.000000  0.000000  0.000000\n",
      "aid_centers             0.988099   0.000000  0.000000  0.000000\n",
      "other_infrastructure    0.962771   0.000000  0.000000  0.000000\n",
      "weather_related         0.765944   0.933511  0.188710  0.313953\n",
      "floods                  0.921269   1.000000  0.026415  0.051471\n",
      "storm                   0.901434   0.850000  0.025758  0.050000\n",
      "fire                    0.989777   0.000000  0.000000  0.000000\n",
      "earthquake              0.913183   0.911765  0.099200  0.178932\n",
      "cold                    0.980012   0.000000  0.000000  0.000000\n",
      "other_weather           0.947818   0.000000  0.000000  0.000000\n",
      "direct_report           0.810497   0.931034  0.041796  0.080000\n",
      "-----------------------------------------------\n",
      "The average accuracy score among all categories is 0.9333,\n",
      "the average precision score score among all categories is 0.3809,\n",
      "the average recall score among all categories is 0.0529,\n",
      "the average F 1 score among all categories is 0.0644\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(best_randomforest, X_test, y_test,category_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pickle** is the standard way of serializing objects in Python.You can use the pickle operation to serialize your machine learning algorithms and save the serialized format to a file.\n",
    "\n",
    "Later you can load this file to deserialize your model and use it to make new predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'best_randomforest.pkl'\n",
    "pickle.dump(pipeline, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Use this notebook to complete `train.py`\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database and export a model based on a new dataset specified by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
